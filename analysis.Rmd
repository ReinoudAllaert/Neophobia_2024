---
title: "Neophobia analysis"
output:
  html_document:
    df_print: paged
---

## Setup

Load and install R packages:

```{r Dependencies, echo=TRUE}
packages <- c('lmerTest', 'lme4', 'ggplot2', 'tidyverse', 'readxl', 'purrr', 'performance', 'emmeans', 'MASS', 'dplyr', 'tidyr', 'nlme', 'mvtnorm', 'lattice')

# Check if each package is installed; if not, install it
for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  library(pkg, character.only = TRUE)
}

```

## Data Loading

Grab `neophobia_data.csv` from `processed_data` directory:

```{r Load data}
script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# Set the working directory to the script's directory
setwd(script_dir)
data <- read.csv("processed_data/neophobia_data.csv", row.names = 1)

```

## Quick Data Inspection

### Filter out LBBG

Summary statistics of the data:

```{r data summary, fig.width=10, fig.height=10, dpi=300}
# Quick look at structure
str(data)
summary(data)

# 13 birds were ID'd to be LBBG instead of HG, in the RR we stated  we would remove those from the analysis:

LBBG <- c("GY_RY", "BG_RR", "GR_GR", "GG_BR",
          "BG_BY", "GY_PP", "PR_BP", "PY_BY",
          "BP_BY", "BB_RR", "GG_BG", "BB_GY",
          "PR_RY")

data <- data %>% filter(!Bird_ID %in% LBBG)

# There are quite a bit of birds that never ate, let's explore those:
data_not_eat <- data %>% filter(Latency_to_Eat == 600)

# 13/29 not eating trials are from birds that did not eat twice or more 
sort(table(data_not_eat$Bird_ID), decreasing = TRUE)

data_not_eat <- data_not_eat %>%
  group_by(Object, Context) %>%
  summarise(Count = n())
data_not_eat$obj_cont <- paste0(data_not_eat$Object, "_", data_not_eat$Context)

# Almost all of those ocurrences are individual x novel
data_not_eat

# Given that these are actually the most interesting birds, we should keep them in the analysis. There are only 106 individual x novel trials in total. Excluding 29 of them  would mean losing 1/3 of the data.

```

## Data Preprocessing

### Missing Group ID Values

The `GroupID` values are currently coded as `NA` during individual trials. Assign the most frequent group for each bird:

```{r Add grp values}
most_frequent_group <- function(group_ids) {
  group_ids <- group_ids[!is.na(group_ids)]
  if (length(group_ids) == 0) return(NA)
  names(sort(table(group_ids), decreasing = TRUE))[1]
}

most_frequent_group_per_bird <- data %>%
  group_by(Bird_ID) %>%
  summarize(most_frequent_group = most_frequent_group(GroupID)) %>%
  ungroup()

data <- data %>%
  left_join(most_frequent_group_per_bird, by = "Bird_ID") %>%
  mutate(GroupID = ifelse(is.na(GroupID), most_frequent_group, GroupID)) %>%
  dplyr::select(-most_frequent_group)
```

### Adjusting Trial Numbers, so the baseline is the first trial rather than 0.

Adjust the `Trial` variable by subtracting 1:

```{r Set trial nbr}
data$Trial <- data$Trial - 1

```

## Statistical Modeling

Given the non-normality of the data we tried to fit 1) DV as is, 2) log(DV), 3) boxcox(DV), going through these steps where necessary.

### 1) Latency to Enter

The full model as described in the RR, includes `Object_contrast`, `Context_contrast`, and `Trial`, and a complex random effect structure:

```{r Enter model 1, fig.width=10, fig.height=10, dpi=300}
enter_model <- lmer(Latency_to_enter ~ Object_contrast * Context_contrast + Trial + 
                (1 | NestID) + 
                (-1 + group_dummy | GroupID) + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model)
check_model(enter_model)

```

The random effect structure seems to be too complex for the amount of data. However, the variance for the `(Intercept)` under `NestID` is `0` and the variance for `group_dummy` under `GroupID` is `0`. This suggests that both nest as differences between groups contribute minimally to the variance in the outcome model. Let's drop both effects.

```{r Enter model 2, fig.width=10, fig.height=10, dpi=300}
enter_model2 <- lmer(Latency_to_enter ~ Object_contrast * Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model2)
check_model(enter_model2)
```

Seems like the interaction between object and context is non-significant, let's drop it. Given the non-normal distribution, let's logtransform the data as well:

```{r Enter model 3, fig.width=10, fig.height=10, dpi=300}
enter_model3 <- lmer(log(Latency_to_enter) ~ Object_contrast + Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model3)
check_model(enter_model3)

```

There are still issues with the data distribution, let's boxcox_transform:

```{r Enter model 4, fig.width=10, fig.height=10, dpi=300}

boxcox_transform <- boxcox(lm(Latency_to_enter ~ Object_contrast + Context_contrast + Trial, data = data))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]
best_lambda
data$Latency_to_enter_trans <- (data$Latency_to_enter^best_lambda - 1) / best_lambda

enter_model4_boxcox <- lmer(Latency_to_enter_trans ~ Object_contrast + 
                              Context_contrast + Trial + 
                            (-1 + ind_dummy + group_dummy | Bird_ID), 
                            data = data)
summary(enter_model4_boxcox)
check_model(enter_model4_boxcox)
```

Comparing the different models, the boxcox transfromed comes out as best. Now let's backtransform the values, for interpretation:

```{r Backtransform, fig.width=10, fig.height=10, dpi=300}
## First the fixed effects
bctran_enter <- make.tran("boxcox", best_lambda) 


# Compute marginal means for Context_contrast
emms_context <- emmeans(
  enter_model4_boxcox,
  specs = "Context_contrast",  # Marginal means for Context_contrast
  type = "response",
  tran = bctran_enter  # Back-transform using Box-Cox transformation
)
print(emms_context)

# Compute marginal means for Object_contrast
emms_object <- emmeans(
  enter_model4_boxcox,
  specs = "Object_contrast",  # Marginal means for Object_contrast
  type = "response",
  tran = bctran_enter  # Back-transform using Box-Cox transformation
)
print(emms_object)

# Compute marginal means for Trial
emms_trial_baseline <- emmeans(
  enter_model4_boxcox,
  specs = ~ Trial,  # Get marginal means for each trial
  at = list(Trial = 0:7),  # trial range (0 to 7)
  type = "response", 
  tran = bctran_enter  
) 
print(emms_trial_baseline) # Clear change in latency over time

# Compare each trial to Trial 0 (the baseline) 
contrast(emms_trial_baseline, "trt.vs.ctrl", ref = 1) 

#### Now look at the variance:

# variances from the model summary 

random_effects_variances <- as.data.frame(VarCorr(enter_model4_boxcox))

# Set seed for reproducibility
set.seed(463)

# Number of birds to simulate
n_birds <- 1000

# Mean vector for the random effects (mean is 0 for both ind and group random effects)
means <- rep(0, 2)

# Construct covariance matrix for the random effects (ind and group)
# random_effects_variances contains the variances and covariances from the model
covar <- matrix(c(random_effects_variances[1, 4],  # Variance for "ind"
                  random_effects_variances[3, 4],  # Covariance between "ind" and "group"
                  random_effects_variances[3, 4],  # Covariance between "ind" and "group" 
                  random_effects_variances[2, 4]), # Variance for "group"
                 byrow = TRUE,
                 ncol = 2,
                 dimnames = list(c("ind", "group"), c("ind", "group")))

# Simulate random effects for 1000 birds, considering the covariance structure
sim_ranefs <- data.frame(rmvnorm(n_birds, mean = means, sigma = covar))

# Rename the columns for clarity
names(sim_ranefs) <- c("ind", "group")

# Check the covariance of the simulated random effects
cov(sim_ranefs)

# Create new data for predicting fixed effects
new_data <- data.frame(
  Trial = 0,  # Keep Trial fixed at 0
  Object = rep(c("control", "novel"), each = 2),  # Two levels: control and novel objects
  Object_contrast = rep(c(-0.5, 0.5), each = 2),  # Contrast coding for Object
  Context = rep(c("ind", "group"), times = 2),    # Two contexts: individual and group
  Context_contrast = rep(c(-0.5, 0.5), times = 2), # Contrast coding for Context
  ind_dummy = rep(c(1, 0), times = 2),  # Dummy coding for individual context
  group_dummy = rep(c(0, 1), times = 2), # Dummy coding for group context
  Bird_ID = "new"  # Arbitrary bird ID to allow prediction
)

# Predict fixed effects using the model (without considering random effects) for the new data
new_data$pred <- predict(enter_model4_boxcox, newdata = new_data, allow.new.levels = TRUE)

# Add the fixed effect predictions to the simulated random effects
# for each combination of object and context

# Individual birds, novel object condition
sim_ranefs$ind_novel <- sim_ranefs$ind + 
  new_data |> filter(Object == "novel", Context == "ind") |> pull(pred)

# Individual birds, control object condition
sim_ranefs$ind_control <- sim_ranefs$ind + 
  new_data |> filter(Object == "control", Context == "ind") |> pull(pred)

# Group birds, novel object condition
sim_ranefs$group_novel <- sim_ranefs$ind + 
  new_data |> filter(Object == "novel", Context == "group") |> pull(pred)

# Group birds, control object condition
sim_ranefs$group_control <- sim_ranefs$ind + 
  new_data |> filter(Object == "control", Context == "group") |> pull(pred)

# Add an ID column to simulate the bird IDs
sim_ranefs$id <- seq_len(n_birds)

# Reshape the data into long format for easier plotting and analysis
plot_data <- sim_ranefs |> pivot_longer(
  cols = c("ind_novel", "ind_control", "group_novel", "group_control"),  # Columns to pivot
  names_sep = "_", 
  names_to = c("cont", "obj"),  # "cont" refers to context, "obj" refers to object type
  values_to = "pred"  # Pivoted values go into the "pred" column
)

# Define the function for back-transforming Box-Cox values
back_transform <- function(simulated_values, lambda = best_lambda) {
  if (lambda != 0) {
    return((simulated_values * lambda + 1)^(1 / lambda))  # Box-Cox back-transformation
  } else {
    return(exp(simulated_values))  # If lambda is 0, apply an exponential transformation
  }
}

# Apply back-transformation to the predictions
plot_data$pred_back <- back_transform(plot_data$pred)

# Replace any NA values in back-transformed predictions with the maximum latency
# This step ensures that all birds have valid back-transformed latency values
plot_data$pred_back[is.na(plot_data$pred_back)] <- max(plot_data$pred_back, na.rm = TRUE)

# Plot the distributions of the Box-Cox transformed random effects
densityplot(~ pred | obj, groups = cont, data = plot_data, auto.key = TRUE,
            main = "Box-Cox Transformed Random Effects Distributions", plot.points = FALSE)

# Plot the distributions of the back-transformed random effects
densityplot(~ pred_back | obj, groups = cont, data = plot_data, auto.key = TRUE,
            main = "Back-Transformed Random Effects Distributions", 
            xlim = c(-1, 10), plot.points = FALSE)

# Reshape the data back to wide format to calculate covariance and correlation
cor_data <- plot_data |> pivot_wider(
  id_cols = id, 
  names_from = c(cont, obj), 
  values_from = pred_back
)

# Calculate covariance and correlation matrices for novel trials
cov(cor_data[, c(2, 4)])  # Covariance between individual and group in novel condition
cor(cor_data[, c(2, 4)])  # Correlation between individual and group in novel condition
sd(cor_data$ind_novel)    # Standard deviation in the individual condition (novel)
sd(cor_data$group_novel)  # Standard deviation in the group condition (novel)

# Calculate covariance and correlation matrices for control trials
cov(cor_data[, c(3, 5)])  # Covariance between individual and group in control condition
cor(cor_data[, c(3, 5)])  # Correlation between individual and group in control condition
sd(cor_data$ind_control)  # Standard deviation in the individual condition (control)
sd(cor_data$group_control) # Standard deviation in the group condition (control)


# Now likelihood ratio test to check whether this sign is different
# Fit model with and without both random effects

# Model 1: Full model with separate variances 
enter_model4_boxcox <- lmer(
  Latency_to_enter_trans ~ Object_contrast + Context_contrast + Trial +
  (-1 + ind_dummy + group_dummy | Bird_ID),
  data = data
)

# Model 2: Reduced model with a single random effect 
enter_model_reduced <- lmer(
  Latency_to_enter_trans ~ Object_contrast + Context_contrast + Trial +
  (1 | Bird_ID),  
  data = data
)

# compare the models using a likelihood ratio test (LRT)
anova(enter_model4_boxcox, enter_model_reduced)

```

**So in conclusion:**

-   **Effect of Context_contrast:**

    -   **Context -0.5 (Individual):** The average latency to approach was **2.07 seconds**.
    -   **Context 0.5 (Group):** The back-transformed average latency to approach was **1.91 seconds**.

    On average, birds took **less time to approach** when in a group compared to when they were alone. Confidence intervals for these estimates do not overlap:

    -   Individual CI: [1.91, 2.26]
    -   Group CI: [1.80, 2.03]

-   **Effect of Object_contrast:**

    -   **Object -0.5 (Control):** The back-transformed average latency to approach was **1.96 seconds**.
    -   **Object 0.5 (Novel):** The back-transformed average latency to approach was **2.01 seconds**.

    Birds took slightly longer to enter in novel conditions compared to control conditions. However, this was **not significant**. Confidence intervals overlap:

    -   Control CI: [1.84, 2.10]
    -   Novel CI: [1.88, 2.16]

-   **Effect of Trial:**

    1.  **Trial 0:** Average latency was **2.94 seconds**.
    2.  **Trial 7:** Average latency was **1.49 seconds**.

    Continuous decrease in latency from **Trial 0** to **Trial 7**.

-   **Variance:**

    -   Original variance in the **individual condition** (Box-Cox transformed scale): 0.0178 seconds² (SD: 0.1336 seconds)
    -   Back-transformed variance in the **individual condition**: 19.38 seconds² (SD: 4.40 seconds)
    -   Original variance in the **group condition** (Box-Cox transformed scale): 0.0057 seconds² (SD: 0.0753 seconds)
    -   Back-transformed variance in the **group condition**: 2.72 seconds² (SD: 1.65 seconds)

    The variance in the individual condition is significantly higher than in the group condition. This result suggests that birds are more consistent when in a group. This was confirmed by the **likelihood ratio test** between the full model (with separate variances for the individual and group conditions) and the reduced model (with a single variance). The full model provided a significantly better fit (p = 0.01063), indicating that the difference in variance between the two conditions is statistically significant.

### 2) Latency to Eat Model

A similar model is built for `Latency_to_Eat`, again incorporating interaction terms and random effects:

```{r Eat model 1, fig.width=10, fig.height=10, dpi=300}
# Given that the distribution of DV is similar to that of the enter model, we log transformed .
eat_model <- lmer(log(Latency_to_Eat) ~ Object_contrast * Context_contrast + Trial + 
                    (1 | NestID) + 
                   (- 1 + group_dummy | GroupID) + 
                   (- 1 + ind_dummy + group_dummy | Bird_ID),  
                 data = data)
summary(eat_model)
check_model(eat_model)
```

Similarly, the variance for the `(Intercept)` under `NestID` is `0` and the variance for `group_dummy` under `GroupID` is `0`. Let's drop those:

```{r Eat model 2, fig.width=10, fig.height=10, dpi=300}

eat_model2 <- lmer(log(Latency_to_Eat) ~ Object_contrast * Context_contrast + Trial + 
                   (- 1 + ind_dummy + group_dummy | Bird_ID),  
                 data = data)
summary(eat_model2)
check_model(eat_model2)

```

There are still some issues with the normality. Let's try the same boxcox tranformation:

```{r Eat model 3, fig.width=10, fig.height=10, dpi=300}

boxcox_transform <- boxcox(lm(Latency_to_Eat ~ Object_contrast * Context_contrast + Trial, data = data))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]
best_lambda
data$Latency_to_eat_trans <- (data$Latency_to_Eat^best_lambda - 1) / best_lambda

eat_model4_boxcox <- lmer(Latency_to_eat_trans ~ Object_contrast * 
                              Context_contrast + Trial + 
                            (-1 + ind_dummy + group_dummy | Bird_ID), 
                            data = data)

summary(eat_model4_boxcox)
check_model(eat_model4_boxcox)

# Given the correlation of 1 and the fact that we still get a singular fit, try to reduce the model
eat_model_reduced <- lmer(Latency_to_eat_trans ~ Object_contrast * Context_contrast + Trial + 
                              (1 | Bird_ID), data = data)
summary(eat_model_reduced)

# Compare the models using a likelihood ratio test (LRT)
anova(eat_model_reduced, eat_model4_boxcox)

# Indeed the full model is not better, so lets continue with the reduved model

```

Now backtransfomr:

```{r Backtransform2, fig.width=10, fig.height=10, dpi=300}
# Ficed effects
# Compute marginal means for the interaction between Object_contrast and Context_contrast, the only interesting fixed effect to look at for this model
emms_interaction_eat <- emmeans(
  eat_model_reduced,
  specs = ~ Object_contrast * Context_contrast,  # Interaction between object and context
  type = "response",                             # Back-transform to original scale
  tran = bctran_enter                            # Apply Box-Cox back-transformation
)
print(emms_interaction_eat)

# not possible to look at random effects

```

**So in conclusion:**

-   **Effect of Context_contrast:**

    -   **Context -0.5 (Individual):** The back-transformed average latency to eat was **5.20 seconds**.
    -   **Context 0.5 (Group):** The back-transformed average latency to eat was **2.96 seconds**.

    On average, birds took **less time to eat** when in a group compared to when they were alone. This effect was statistically significant (p \< 2e-16), and the confidence intervals for these estimates do not overlap:

    -   Individual CI: [4.58, 6.00]
    -   Group CI: [2.73, 3.22]

-   **Effect of Object_contrast:**

    -   **Object -0.5 (Control):** The back-transformed average latency to eat was **5.20 seconds** (in the individual context) and **2.96 seconds** (in the group context).
    -   **Object 0.5 (Novel):** The back-transformed average latency to eat was **9.81 seconds** (in the individual context) and **3.52 seconds** (in the group context).

    Birds took significantly longer to eat in the presence of a **novel object**, and this effect was modified by the social context. In the **individual context**, the latency to eat was much higher for the novel object compared to the control object (significant interaction p = 0.0149). In the group context, this effect was less pronounced. The confidence intervals for these estimates do not overlap:

    -   Novel (Individual) CI: [7.93, 12.72]
    -   Control (Individual) CI: [4.58, 6.00]
    -   Novel (Group) CI: [3.21, 3.89]
    -   Control (Group) CI: [2.73, 3.22]

-   **Effect of Trial:**

    -   The trial effect was **not significant** (p = 0.5904), indicating that the birds' latency to eat did not change significantly over time. So birds did not become desensitized to the novelty.

### 3) Time spent in the zone of interest

```{r ZOI model 2, fig.width=10, fig.height=10, dpi=300}
zoi_model2 <- lmer(Zoi_duration ~ Object_contrast * Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(zoi_model2)
check_model(zoi_model2)
```

try logtransformation, seems to work

```{r ZOI model log, fig.width=10, fig.height=10, dpi=300}
## 
# Log transformation to better handle zeros
data$Log_Zoi_duration <- log(data$Zoi_duration + 1)

# Fit a linear mixed model on the transformed data
zoi_model_log <- lmer(
  Log_Zoi_duration ~ Object_contrast * Context_contrast + Trial + 
    (-1 + ind_dummy + group_dummy | Bird_ID), 
  data = data
)

# Summarize the model
summary(zoi_model_log)
check_model(zoi_model_log)
```

Comparing the different models, the log comes out as best

```{r backtrnafrom, fig.width=10, fig.height=10, dpi=300}
# Function for back-transforming the log-transformed values to seconds
# Back-transform the fixed effects
back_transform_log <- function(predicted_values) {
  # Apply exp() to reverse the log-transformation
  return(exp(predicted_values))
}

# Compute marginal means for the interaction between Object_contrast and Context_contrast
emms_interaction_zoi <- emmeans(
  zoi_model_log,  # The log-transformed model
  specs = ~ Object_contrast * Context_contrast,  # Interaction between object and context
  type = "response"  # Return values on the original (back-transformed) scale
)

# Apply the back-transform function to the emmeans results
predicted_zoi_interaction <- summary(emms_interaction_zoi)
predicted_zoi_interaction$backtransformed_response <- back_transform_log(predicted_zoi_interaction$emmean)

# Print the back-transformed marginal means
print(predicted_zoi_interaction)

# Random effects
random_effects_variances <- as.data.frame(VarCorr(zoi_model_log))

# Set seed for reproducibility
set.seed(463)

# Number of birds to simulate
n_birds <- 1000

# Mean vector for the random effects (mean is 0 for both ind and group random effects)
means <- rep(0, 2)

# Construct covariance matrix for the random effects (ind and group)
# random_effects_variances contains the variances and covariances from the model
covar <- matrix(c(random_effects_variances[1, 4],  # Variance for "ind"
                  random_effects_variances[3, 4],  # Covariance between "ind" and "group"
                  random_effects_variances[3, 4],  # Covariance between "ind" and "group" 
                  random_effects_variances[2, 4]), # Variance for "group"
                 byrow = TRUE,
                 ncol = 2,
                 dimnames = list(c("ind", "group"), c("ind", "group")))

# Simulate random effects for 1000 birds, considering the covariance structure
sim_ranefs <- data.frame(rmvnorm(n_birds, mean = means, sigma = covar))

# Rename the columns for clarity
names(sim_ranefs) <- c("ind", "group")

# Check the covariance of the simulated random effects
cov(sim_ranefs)

# Create new data for predicting fixed effects
new_data <- data.frame(
  Trial = 0,  # Keep Trial fixed at 0
  Object = rep(c("control", "novel"), each = 2),  # Two levels: control and novel objects
  Object_contrast = rep(c(-0.5, 0.5), each = 2),  # Contrast coding for Object
  Context = rep(c("ind", "group"), times = 2),    # Two contexts: individual and group
  Context_contrast = rep(c(-0.5, 0.5), times = 2), # Contrast coding for Context
  ind_dummy = rep(c(1, 0), times = 2),  # Dummy coding for individual context
  group_dummy = rep(c(0, 1), times = 2), # Dummy coding for group context
  Bird_ID = "new"  # Arbitrary bird ID to allow prediction
)

# Predict fixed effects using the model (without considering random effects) for the new data
new_data$pred <- predict(zoi_model_log, newdata = new_data, allow.new.levels = TRUE)

# Add the fixed effect predictions to the simulated random effects
# for each combination of object and context

# Individual birds, novel object condition
sim_ranefs$ind_novel <- sim_ranefs$ind + 
  new_data |> filter(Object == "novel", Context == "ind") |> pull(pred)

# Individual birds, control object condition
sim_ranefs$ind_control <- sim_ranefs$ind + 
  new_data |> filter(Object == "control", Context == "ind") |> pull(pred)

# Group birds, novel object condition
sim_ranefs$group_novel <- sim_ranefs$ind + 
  new_data |> filter(Object == "novel", Context == "group") |> pull(pred)

# Group birds, control object condition
sim_ranefs$group_control <- sim_ranefs$ind + 
  new_data |> filter(Object == "control", Context == "group") |> pull(pred)

# Add an ID column to simulate the bird IDs
sim_ranefs$id <- seq_len(n_birds)

# Reshape the data into long format for easier plotting and analysis
plot_data <- sim_ranefs |> pivot_longer(
  cols = c("ind_novel", "ind_control", "group_novel", "group_control"),  # Columns to pivot
  names_sep = "_", 
  names_to = c("cont", "obj"),  # "cont" refers to context, "obj" refers to object type
  values_to = "pred"  # Pivoted values go into the "pred" column
)

# Defined the function for back-transforming log above

# Apply back-transformation to the predictions
plot_data$pred_back <- back_transform_log(plot_data$pred)

# Replace any NA values in back-transformed predictions with the maximum latency
# This step ensures that all birds have valid back-transformed latency values
plot_data$pred_back[is.na(plot_data$pred_back)] <- max(plot_data$pred_back, na.rm = TRUE)

# Plot the distributions of the Box-Cox transformed random effects
densityplot(~ pred | obj, groups = cont, data = plot_data, auto.key = TRUE,
            main = "Box-Cox Transformed Random Effects Distributions", plot.points = FALSE)

# Plot the distributions of the back-transformed random effects
densityplot(~ pred_back | obj, groups = cont, data = plot_data, auto.key = TRUE,
            main = "Back-Transformed Random Effects Distributions", 
            xlim = c(-1, 10), plot.points = FALSE)

# Reshape the data back to wide format to calculate covariance and correlation
cor_data <- plot_data |> pivot_wider(
  id_cols = id, 
  names_from = c(cont, obj), 
  values_from = pred_back
)

# Calculate covariance and correlation matrices for novel trials
cov(cor_data[, c(2, 4)])  # Covariance between individual and group in novel condition
cor(cor_data[, c(2, 4)])  # Correlation between individual and group in novel condition
sd(cor_data$ind_novel)    # Standard deviation in the individual condition (novel)
sd(cor_data$group_novel)  # Standard deviation in the group condition (novel)

# Calculate covariance and correlation matrices for control trials
cov(cor_data[, c(3, 5)])  # Covariance between individual and group in control condition
cor(cor_data[, c(3, 5)])  # Correlation between individual and group in control condition
sd(cor_data$ind_control)  # Standard deviation in the individual condition (control)
sd(cor_data$group_control) # Standard deviation in the group condition (control)

# Test difference in variance
# Full model: Separate random effects for individual and group conditions
zoi_model_log_full <- lmer(
  Log_Zoi_duration ~ Object_contrast * Context_contrast + Trial +
  (-1 + ind_dummy + group_dummy | Bird_ID),
  data = data
)

# Reduced model: Single random effect for Bird_ID
zoi_model_log_reduced <- lmer(
  Log_Zoi_duration ~ Object_contrast * Context_contrast + Trial +
  (1 | Bird_ID),
  data = data
)

# Compare the models using a likelihood ratio test (LRT)
anova(zoi_model_log_full, zoi_model_log_reduced)

```

**So in conclusion:**

-   **Effect of Context_contrast:**

    -   **Control object in the individual condition:**
        -   Non-back-transformed ZOI duration: **4.59** seconds.

        -   Back-transformed ZOI duration: **98.4** seconds.

    ```{=html}
    <!-- -->
    ```
    -   **Control object in the group condition:**

        -   Non-back-transformed ZOI duration: **4.38** seconds.

        -   Back-transformed ZOI duration: **80.2** seconds.

    -   **Novel object in the individual condition:**

        -   Non-back-transformed ZOI duration: **3.66** seconds.

        -   Back-transformed ZOI duration: **38.8** seconds.

    -   **Novel object in the group condition:**

        -   Non-back-transformed ZOI duration: **4.72** seconds.

        -   Back-transformed ZOI duration: **111.8** seconds.

    There was a significant interaction between object type and social context. Birds spent more time in the ZOI when exposed to novel objects in groups, compared to when alone, while they spent more time in the ZOI with control objects when alone than in groups. This interaction was statistically significant (**p \< 0.00001**).

    **Effect of Trial:**

    -   **Trial 0:**

        -   Non-back-transformed ZOI duration: **4.11** seconds.

        -   Back-transformed ZOI duration: **60** seconds.

    -   **Trial 7:**

        -   Non-back-transformed ZOI duration: **4.81** seconds.

        -   Back-transformed ZOI duration: **94.9** seconds.

    ZOI duration increased steadily over time, with each trial showing progressively longer ZOI duration. The confidence intervals for the trials were:

    -   **Trial 0 CI:** [3.86, 4.36] (Back-transformed: 60 seconds).

    -   **Trial 7 CI:** [4.32, 4.81] (Back-transformed: 94.9 seconds).

    Significant differences were found between trial 0 and all other trials (**p = 0.0321**).

    **Variance:**

    -   **Variance in the individual condition (Control):**

        -   Non-back-transformed variance: **0.73** seconds² (SD: **0.85** seconds).

        -   Back-transformed variance: **1728** seconds² (SD: **41.57** seconds).

    -   **Variance in the group condition (Control):**

        -   Non-back-transformed variance: **0.18** seconds² (SD: **0.43** seconds).

        -   Back-transformed variance: **14317** seconds² (SD: **119.65** seconds).

    -   **Variance in the individual condition (Novel):**

        -   Non-back-transformed variance: **1.18** seconds² (SD: **1.09** seconds).

        -   Back-transformed variance: **11077** seconds² (SD: **105.25** seconds).

    -   **Variance in the group condition (Novel):**

        -   Non-back-transformed variance: **0.18** seconds² (SD: **0.43** seconds).

        -   Back-transformed variance: **7367** seconds² (SD: **85.83** seconds).

    Variance was higher in group settings, especially when birds were exposed to novel objects. The likelihood ratio test indicated that the full model, with separate random effects for individual and group conditions, fit the data significantly better than the reduced model with a single random effect.Multivariate analysis

Now fit a multivariate model:

```{r multivariate model 1}
# make data long:
data_long <- data %>%
  pivot_longer(
    cols = c(Latency_to_enter, Latency_to_Eat),
    names_to = "Behaviour_Type",
    values_to = "Latency"
  )
data_long <- data_long %>%
  mutate(
    eat_vs_leave_contrast = case_when(
      Behaviour_Type == "Latency_to_enter" ~ -0.5,
      Behaviour_Type == "Latency_to_Eat" ~ 0.5
    )
  )

# fir full model
latency_model <- lmer(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (1 | NestID) +
                    (- 1 + group_dummy | GroupID) + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model)

```

Same as before, reduce the model:

```{r multivariate model 2, fig.width=10, fig.height=10, dpi=300}

latency_model2 <- lmer(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model2)
check_model(latency_model2)

```

Same as before, boxcox transfrom the data:

```{r multivariate model 3, fig.width=10, fig.height=10, dpi=300}


boxcox_transform <- boxcox(lm(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial, data = data_long))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]

data_long$Latency_trans <- (data_long$Latency^best_lambda - 1) / best_lambda



latency_model3_boxcox <- lmer(Latency_trans ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model3_boxcox)
check_model(latency_model3_boxcox)


```

There are still issues with the ranef structure, simpligy the model:

```{r multivariate model 4, fig.width=10, fig.height=10, dpi=300}
latency_model3_boxcox_reduced <- lmer(Latency_trans ~ eat_vs_leave_contrast * Object_contrast * Context_contrast +
                                       Trial + 
                                       (-1 + ind_dummy + group_dummy  | Bird_ID), 
                                     data = data_long)

# Summary of the updated model
summary(latency_model3_boxcox_reduced)

# Check the model diagnostics
check_model(latency_model3_boxcox_reduced)
```

I would say the multivariate model supports what the we found earlier. 3-way interaction is nonsign, so lets remove it:

```{r multivariate model 5, fig.width=10, fig.height=10, dpi=300}
latency_model3_boxcox_reduced_2 <- lmer(
  Latency_trans ~ eat_vs_leave_contrast * Object_contrast + 
                  eat_vs_leave_contrast * Context_contrast + 
                  Object_contrast * Context_contrast + 
                  Trial + 
                  (-1 + ind_dummy + group_dummy | Bird_ID), 
  data = data_long
)

# Summary of the updated model
summary(latency_model3_boxcox_reduced_2)

# Check the model diagnostics
check_model(latency_model3_boxcox_reduced_2)
```

############################################################################## 

############################################################################## 

```{r Descriptives}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(ggsignif)
library(patchwork)

# Calculate summary stats for plotting (mean and standard error)
calculate_summary <- function(data, var) {
  data %>%
    group_by(Context, Object) %>%
    summarise(mean_value = mean({{var}}, na.rm = TRUE),
              se_value = sd({{var}}, na.rm = TRUE) / sqrt(n()),
              .groups = "drop")
}

# Summarise data for each variable
summary_latency_enter <- data %>%
  group_by(Context) %>%
  summarise(mean_value = mean(Latency_to_enter, na.rm = TRUE),
            se_value = sd(Latency_to_enter, na.rm = TRUE) / sqrt(n()))

summary_latency_eat <- calculate_summary(data, Latency_to_Eat)
summary_time_ZOI <- calculate_summary(data, Zoi_duration)

# Custom function to reorder factor levels for plots
reorder_levels <- function(data) {
  data <- data %>%
    mutate(Context_Object = interaction(Context, Object, sep = "-")) %>%
    mutate(Context_Object = factor(Context_Object, 
                                   levels = c("individual-control", "individual-novel", 
                                              "group-control", "group-novel")))
  return(data)
}

# Reorder levels for the interaction-based data
summary_latency_eat <- reorder_levels(summary_latency_eat)
summary_time_ZOI <- reorder_levels(summary_time_ZOI)

# Function to plot Latency to Enter (no Object, Context only)
plot_latency_enter <- ggplot(summary_latency_enter, aes(x = Context, y = mean_value, fill = Context)) + 
  geom_bar(stat = "identity", position = position_dodge(), width = 0.6) + 
  geom_errorbar(aes(ymin = mean_value - se_value, ymax = mean_value + se_value), 
                width = 0.2, position = position_dodge(0.6)) + 
  labs(x = "", y = "Mean Latency (s)", title = "Latency to Enter") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, , size = 12), 
        plot.title = element_text(hjust = 0.5, size = 14), 
        axis.title = element_text(size = 12),
        legend.position = "none") + 
  scale_fill_manual(values = c("group" = "goldenrod", "individual" = "lightblue")) 

# Function to plot variables with interaction (Latency to Eat, ZOI Duration) and double brackets
plot_variable_with_double_brackets <- function(data, var_name, y_label) {
  ggplot(data, aes(x = Context_Object, y = mean_value, fill = Object)) + 
    geom_bar(stat = "identity", position = position_dodge(), width = 0.6) + 
    geom_errorbar(aes(ymin = mean_value - se_value, ymax = mean_value + se_value), 
                  width = 0.2, position = position_dodge(0.6)) + 
    labs(x = "", y = y_label, title = var_name) + 
    theme_classic() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12), 
          plot.title = element_text(hjust = 0.5, size = 14), 
          axis.title = element_text(size = 12),
          legend.position = "none") + 
    scale_fill_manual(values = c("novel" = "goldenrod", "control" = "lightblue"))
}

# Plot Latency to Eat
plot_latency_eat <- plot_variable_with_double_brackets(summary_latency_eat, "Latency to Eat", "Mean Latency (s)")

# Plot Time Spent in ZOI
plot_time_ZOI <- plot_variable_with_double_brackets(summary_time_ZOI, "ZOI Duration", "Mean Time (s)")

# Combine plots using patchwork
combined_plot <- (plot_latency_enter | plot_latency_eat | plot_time_ZOI) + 
  plot_layout(guides = 'collect') + 
  plot_annotation(tag_levels = 'A') &
  theme(plot.tag.position = "bottom")

# Print the combined plot
print(combined_plot)



```

# Plot the Object x Context interaction

```{r Plot of descriptives}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(patchwork)

# Calculate summary stats for plotting (mean and standard error)
calculate_summary <- function(data, var) {
  data %>%
    group_by(Context, Object) %>%
    summarise(mean_value = mean({{var}}, na.rm = TRUE),
              se_value = sd({{var}}, na.rm = TRUE) / sqrt(n()),
              .groups = "drop")
}

# Summarise data for each variable
summary_latency_enter <- data %>%
  group_by(Context) %>%
  summarise(mean_value = mean(Latency_to_enter, na.rm = TRUE),
            se_value = sd(Latency_to_enter, na.rm = TRUE) / sqrt(n()))

summary_latency_eat <- calculate_summary(data, Latency_to_Eat)
summary_time_ZOI <- calculate_summary(data, Zoi_duration)

# Custom function to reorder factor levels for plots
reorder_levels <- function(data) {
  data <- data %>%
    mutate(Context_Object = interaction(Context, Object, sep = "-")) %>%
    mutate(Context_Object = factor(Context_Object, 
                                   levels = c("individual-control", "individual-novel", 
                                              "group-control", "group-novel")))
  return(data)
}

# Reorder levels for the interaction-based data
summary_latency_eat <- reorder_levels(summary_latency_eat)
summary_time_ZOI <- reorder_levels(summary_time_ZOI)

# Function to plot Latency to Enter (no Object, Context only)
plot_latency_enter <- ggplot(summary_latency_enter, aes(x = Context, y = mean_value, fill = Context)) + 
  geom_bar(stat = "identity", position = position_dodge(), width = 0.6) + 
  geom_errorbar(aes(ymin = mean_value - se_value, ymax = mean_value + se_value), 
                width = 0.2, position = position_dodge(0.6)) + 
  labs(x = "", y = "Mean Latency (s)", title = "Latency to Enter") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), 
        plot.title = element_text(hjust = 0.5, size = 14), 
        axis.title = element_text(size = 12),
        legend.position = "none") + 
  scale_fill_manual(values = c("group" = "goldenrod", "individual" = "lightblue"))

# Function to plot variables with interaction (Latency to Eat, ZOI Duration)
plot_variable_without_signif <- function(data, var_name, y_label) {
  ggplot(data, aes(x = Context_Object, y = mean_value, fill = Object)) + 
    geom_bar(stat = "identity", position = position_dodge(), width = 0.6) + 
    geom_errorbar(aes(ymin = mean_value - se_value, ymax = mean_value + se_value), 
                  width = 0.2, position = position_dodge(0.6)) + 
    labs(x = "", y = y_label, title = var_name) + 
    theme_classic() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), 
          plot.title = element_text(hjust = 0.5, size = 14), 
          axis.title = element_text(size = 12),
          legend.position = "none") + 
    scale_fill_manual(values = c("novel" = "goldenrod", "control" = "lightblue"))
}

# Plot Latency to Eat
plot_latency_eat <- plot_variable_without_signif(summary_latency_eat, "Latency to Eat", "Mean Latency (s)")

# Plot Time Spent in ZOI
plot_time_ZOI <- plot_variable_without_signif(summary_time_ZOI, "ZOI Duration", "Mean Time (s)")

# Combine plots using patchwork
combined_plot <- (plot_latency_enter | plot_latency_eat | plot_time_ZOI) + 
  plot_layout(guides = 'collect') + 
  plot_annotation(tag_levels = 'A') &
  theme(plot.tag.position = "bottom")

# Print the combined plot
print(combined_plot)




```
