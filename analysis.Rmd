---
title: "Neophobia analysis"
output:
  html_document:
    df_print: paged
---

## Setup

Load and install R packages:

```{r Dependencies, echo=TRUE}
packages <- c('lmerTest', 'lme4', 'ggplot2', 'tidyverse', 'readxl', 'purrr', 'performance', 'emmeans', 'MASS', 'dplyr', 'tidyr', 'nlme')

# Check if each package is installed; if not, install it
for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  library(pkg, character.only = TRUE)
}

```

## Data Loading

Grab `neophobia_data.csv` from `processed_data` directory:

```{r Load data}
script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# Set the working directory to the script's directory
setwd(script_dir)
data <- read.csv("processed_data/neophobia_data.csv", row.names = 1)

```

## Quick Data Inspection

### Filter out LBBG

Summary statistics of the data:

```{r data summary, fig.width=10, fig.height=10, dpi=300}
# Quick look at structure
str(data)
summary(data)

# 13 birds were ID'd to be LBBG instead of HG, in the RR we stated  we would remove those from the analysis:

LBBG <- c("GY_RY", "BG_RR", "GR_GR", "GG_BR",
          "BG_BY", "GY_PP", "PR_BP", "PY_BY",
          "BP_BY", "BB_RR", "GG_BG", "BB_GY",
          "PR_RY")

data <- data %>% filter(!Bird_ID %in% LBBG)

# There are quite a bit of birds that never ate, let's explore those:
data_not_eat <- data %>% filter(Latency_to_Eat == 600)

# 13/29 not eating trials are from birds that did not eat twice or more 
sort(table(data_not_eat$Bird_ID), decreasing = TRUE)

data_not_eat <- data_not_eat %>%
  group_by(Object, Context) %>%
  summarise(Count = n())
data_not_eat$obj_cont <- paste0(data_not_eat$Object, "_", data_not_eat$Context)

# Almost all of those ocurrences are individual x novel
data_not_eat

# Given that these are actually the most interesting birds, we should keep them in the analysis. There are only 106 individual x novel trials in total. Excluding 29 of them  would mean losing 1/3 of the data.

```

## Data Preprocessing

### Missing Group ID Values

The `GroupID` values are currently coded as `NA` during individual trials. Assign the most frequent group for each bird:

```{r Add grp values}
most_frequent_group <- function(group_ids) {
  group_ids <- group_ids[!is.na(group_ids)]
  if (length(group_ids) == 0) return(NA)
  names(sort(table(group_ids), decreasing = TRUE))[1]
}

most_frequent_group_per_bird <- data %>%
  group_by(Bird_ID) %>%
  summarize(most_frequent_group = most_frequent_group(GroupID)) %>%
  ungroup()

data <- data %>%
  left_join(most_frequent_group_per_bird, by = "Bird_ID") %>%
  mutate(GroupID = ifelse(is.na(GroupID), most_frequent_group, GroupID)) %>%
  dplyr::select(-most_frequent_group)
```

### Adjusting Trial Numbers, so the baseline is the first trial rather than 0.

Adjust the `Trial` variable by subtracting 1:

```{r Set trial nbr}
data$Trial <- data$Trial - 1

```

## Statistical Modeling

### 1) Latency to Enter

The full model as described in the RR, includes `Object_contrast`, `Context_contrast`, and `Trial`, and a complex random effect structure:

```{r Enter model 1, fig.width=10, fig.height=10, dpi=300}
enter_model <- lmer(Latency_to_enter ~ Object_contrast * Context_contrast + Trial + 
                (1 | NestID) + 
                (-1 + group_dummy | GroupID) + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model)
check_model(enter_model)

```

The random effect structure seems to be too complex for the amount of data. However, the variance for the `(Intercept)` under `NestID` is `0` and the variance for `group_dummy` under `GroupID` is `0`. This suggests that both nest as differences between groups contribute minimally to the variance in the outcome model. Let's drop both effects.

```{r Enter model 2, fig.width=10, fig.height=10, dpi=300}
enter_model2 <- lmer(Latency_to_enter ~ Object_contrast * Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model2)
check_model(enter_model2)
```

Seems like the interaction between object and context is non-significant, let's drop it. Given the non-normal distribution, let's logtransform the data as well:

```{r Enter model 3, fig.width=10, fig.height=10, dpi=300}
enter_model3 <- lmer(log(Latency_to_enter) ~ Object_contrast + Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(enter_model3)
check_model(enter_model3)

```

There are still issues with the data distribution, let's boxcox_transform:

```{r Enter model 4, fig.width=10, fig.height=10, dpi=300}

boxcox_transform <- boxcox(lm(Latency_to_enter ~ Object_contrast + Context_contrast + Trial, data = data))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]

data$Latency_to_enter_trans <- (data$Latency_to_enter^best_lambda - 1) / best_lambda

enter_model4_boxcox <- lmer(Latency_to_enter_trans ~ Object_contrast + 
                              Context_contrast + Trial + 
                            (-1 + ind_dummy + group_dummy | Bird_ID), 
                            data = data)
summary(enter_model4_boxcox)
check_model(enter_model4_boxcox)
```

Comparing the different models, the boxcox transfromed comes out as best:

```{r Compare entering models}
anova(enter_model, enter_model2, enter_model3, enter_model4_boxcox)
```

### 2) Latency to Eat Model

A similar model is built for `Latency_to_Eat`, again incorporating interaction terms and random effects:

```{r Eat model 1, fig.width=10, fig.height=10, dpi=300}
# Given that the distribution of DV is similar to that of the enter model, we log transformed .
eat_model <- lmer(log(Latency_to_Eat) ~ Object_contrast * Context_contrast + Trial + 
                    (1 | NestID) + 
                   (- 1 + group_dummy | GroupID) + 
                   (- 1 + ind_dummy + group_dummy | Bird_ID),  
                 data = data)
summary(eat_model)
check_model(eat_model)
```

Similarly, the variance for the `(Intercept)` under `NestID` is `0` and the variance for `group_dummy` under `GroupID` is `0`. Let's drop those:

```{r Eat model 2, fig.width=10, fig.height=10, dpi=300}

eat_model2 <- lmer(log(Latency_to_Eat) ~ Object_contrast * Context_contrast + Trial + 
                   (- 1 + ind_dummy + group_dummy | Bird_ID),  
                 data = data)
summary(eat_model2)
check_model(eat_model2)

```

There are still some issues with the normality. Let's try the same boxcox tranformation:

```{r Eat model 3, fig.width=10, fig.height=10, dpi=300}

boxcox_transform <- boxcox(lm(Latency_to_Eat ~ Object_contrast * Context_contrast + Trial, data = data))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]

data$Latency_to_eat_trans <- (data$Latency_to_Eat^best_lambda - 1) / best_lambda

eat_model4_boxcox <- lmer(Latency_to_eat_trans ~ Object_contrast * 
                              Context_contrast + Trial + 
                            (-1 + ind_dummy + group_dummy | Bird_ID), 
                            data = data)

summary(eat_model4_boxcox)
check_model(eat_model4_boxcox)
```

boxcox model seems to fit data best, but still a correlation of 1, which is problematic... Potentially use nlme?

```{r}
eat_model_nlme <- lme(Latency_to_eat_trans ~ Object_contrast * Context_contrast + Trial, 
                      random = ~ 1 | Bird_ID,
                      weights = varIdent(form = ~ 1 | Context),  
                      data = data)

summary(eat_model_nlme)
check_model(eat_model_nlme)
```

Or model contexts separately?

```{r}
# model for group context
eat_model_group <- lmer(Latency_to_eat_trans ~ Object_contrast + Trial + 
                        (1 | Bird_ID), 
                        data = subset(data, Context == "group"))

# model for individual context
eat_model_alone <- lmer(Latency_to_eat_trans ~ Object_contrast  + Trial + 
                        (1 | Bird_ID), 
                        data = subset(data, Context == "individual"))

# Compare variances
summary(eat_model_group)
summary(eat_model_alone)
```

```{r Compare eat models}

anova(eat_model, eat_model2, eat_model4_boxcox)

```

### 3) Time spent in the ZOI

The full model as described in the RR, includes `Object_contrast`, `Context_contrast`, and `Trial`, and a complex random effect structure:

```{r ZOI model 1, fig.width=10, fig.height=10, dpi=300}
zoi_model <- lmer(Zoi_duration ~ Object_contrast * Context_contrast + Trial + 
                (1 | NestID) + 
                (-1 + group_dummy | GroupID) + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(zoi_model)
check_model(zoi_model)

```

Here the full model seems to fit, lets try with a simpeler ranef structure though:

```{r ZOI model 2, fig.width=10, fig.height=10, dpi=300}
zoi_model2 <- lmer(Zoi_duration ~ Object_contrast * Context_contrast + Trial + 
                (-1 +  ind_dummy + group_dummy | Bird_ID), 
              data = data)

summary(zoi_model2)
check_model(zoi_model2)
```

There are still issues with the data distribution, let's boxcox_transform:

```{r ZOI model 3, fig.width=10, fig.height=10, dpi=300}

boxcox_transform <- boxcox(lm(Zoi_duration+ 0.01 ~ Object_contrast * Context_contrast + Trial, data = data))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]

data$Latency_to_zoi_trans <- (data$Zoi_duration^best_lambda - 1) / best_lambda

zoi_model4_boxcox <- lmer(Latency_to_zoi_trans ~ Object_contrast * 
                              Context_contrast + Trial + 
                            (-1 + ind_dummy + group_dummy | Bird_ID), 
                            data = data)
summary(zoi_model4_boxcox)
check_model(zoi_model4_boxcox)
```

Comparing the different models, the boxcox comes out as best:

```{r Compare ZOI models}

anova(zoi_model, zoi_model2, zoi_model4_boxcox)

```

So we end up with these models:

```{r Summarise models}
# To enter
summary(enter_model4_boxcox)

# To eat
summary(eat_model4_boxcox)

# Time near object
summary(zoi_model4_boxcox)
```

#### So for entering:

##### Fixed Effects:

Context is significant, with birds being faster in groups compared to being alone. In addition trial is significant, with birds becoming faster over time.

##### Random Effects:

Variance: The variance is higher for individual trials, suggesting that there is more variability in how long birds take to enter when they are alone.

#### So for eating:

##### Fixed Effects:

Object_contrast: Birds take longer to start eating when the object is novel. Context_contrast: Birds are quicker to eat when they are in a group compared to when they are alone.

##### Random Effects:

Variance: There is slightly more variability in the latency to eat during individual trials, indicating that birds' responses to novelty are more variable when they are alone. However the values are in the same ballpark.

#### So for ZOI:

##### Fixed Effects:

Context_contrast: Birds spend more time near objects when they are in a group compared to when they are alone. Trial: Time near objects increases over time. Interaction between Object_contrast and Context_contrast: Suggests that the effect of object novelty on the time spent near the object depends on whether the birds are alone or in a group. In a group, birds may be more willing to spend time near a novel object, while alone, they might avoid it more quickly.

##### Random Effects:

Variance: The variance is higher for individual trials, indicating variability in how long individual birds spend near novel objects when they are alone. Potentially reflects differences in individual boldness or fearfulness in the absence of a group.

## Multivariate analysis

Now fit a multivariate model:

```{r multivariate model 1}
# make data long:
data_long <- data %>%
  pivot_longer(
    cols = c(Latency_to_enter, Latency_to_Eat),
    names_to = "Behaviour_Type",
    values_to = "Latency"
  )
data_long <- data_long %>%
  mutate(
    eat_vs_leave_contrast = case_when(
      Behaviour_Type == "Latency_to_enter" ~ -0.5,
      Behaviour_Type == "Latency_to_Eat" ~ 0.5
    )
  )

# fir full model
latency_model <- lmer(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (1 | NestID) +
                    (- 1 + group_dummy | GroupID) + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model)

```

Same as before, reduce the model:

```{r multivariate model 2, fig.width=10, fig.height=10, dpi=300}

latency_model2 <- lmer(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model2)
check_model(latency_model2)

```

Same as before, boxcox transfrom the data:

```{r multivariate model 3, fig.width=10, fig.height=10, dpi=300}


boxcox_transform <- boxcox(lm(Latency ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial, data = data_long))
best_lambda <- boxcox_transform$x[which.max(boxcox_transform$y)]

data_long$Latency_trans <- (data_long$Latency^best_lambda - 1) / best_lambda



latency_model3_boxcox <- lmer(Latency_trans ~ eat_vs_leave_contrast * Object_contrast * Context_contrast + Trial + 
                    (- 1 + ind_dummy + group_dummy + eat_vs_leave_contrast | Bird_ID), 
                  data = data_long)

summary(latency_model3_boxcox)
check_model(latency_model3_boxcox)


```

There are still issues with the ranef structure, simpligy the model:

```{r multivariate model 4, fig.width=10, fig.height=10, dpi=300}
latency_model3_boxcox_reduced <- lmer(Latency_trans ~ eat_vs_leave_contrast * Object_contrast * Context_contrast +
                                       Trial + 
                                       (-1 + ind_dummy + group_dummy  | Bird_ID), 
                                     data = data_long)

# Summary of the updated model
summary(latency_model3_boxcox_reduced)

# Check the model diagnostics
check_model(latency_model3_boxcox_reduced)
```

I would say the multivariate model supports what the we found earlier. 3-way interaction is nonsign, so lets remove it:

```{r multivariate model 5, fig.width=10, fig.height=10, dpi=300}
latency_model3_boxcox_reduced_2 <- lmer(Latency_trans ~ eat_vs_leave_contrast * Object_contrast +
                                       eat_vs_leave_contrast * Context_contrast +
                                       Object_contrast * Context_contrast +
                                       Trial + 
                                       (-1 + ind_dummy + group_dummy  | Bird_ID), 
                                     data = data_long)

# Summary of the updated model
summary(latency_model3_boxcox_reduced_2)

# Check the model diagnostics
check_model(latency_model3_boxcox_reduced_2)
```

```{r Compare multivariate models }
anova(latency_model3_boxcox_reduced_2, latency_model3_boxcox_reduced, latency_model3_boxcox, latency_model2, latency_model)
```

latency_model3_boxcox seems to be the best fit, but gives warnings.
